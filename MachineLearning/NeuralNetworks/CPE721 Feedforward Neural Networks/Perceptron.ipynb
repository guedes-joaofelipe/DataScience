{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "This notebook contains the implementation for a practical exercise on perceptron studies found on an [Artificial Neural Network book](https://www.amazon.com.br/Neurais-Artificiais-Engenharia-Ci%C3%AAncias-Aplicadas/dp/8588098539), section 3.6. \n",
    "\n",
    "The training set contains information o 3 features extracted from a oil destilation process and 1 target value indicating whether registers belong to one of 2 classes {P1 and P2}, denoted by [-1, 1] respectively. The test set contains only the features of another set of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.11</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.45</td>\n",
       "      <td>0.89</td>\n",
       "      <td>4.40</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.09</td>\n",
       "      <td>0.69</td>\n",
       "      <td>12.07</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.26</td>\n",
       "      <td>1.15</td>\n",
       "      <td>7.80</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.64</td>\n",
       "      <td>1.02</td>\n",
       "      <td>7.04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1    x2     x3  target\n",
       "0 -0.65  0.11   4.00    -1.0\n",
       "1 -1.45  0.89   4.40    -1.0\n",
       "2  2.09  0.69  12.07    -1.0\n",
       "3  0.26  1.15   7.80     1.0\n",
       "4  0.64  1.02   7.04     1.0"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./Datasets/ex3_6_train.tsv', sep='\\t')\n",
    "df_train.drop(['sample'], axis=1, inplace=True)\n",
    "df_test = pd.read_csv('./Datasets/ex3_6_test.tsv', sep='\\t')\n",
    "df_test.drop(['sample'], axis=1, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.06</td>\n",
       "      <td>5.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.78</td>\n",
       "      <td>1.13</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.56</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.78</td>\n",
       "      <td>1.06</td>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.80</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1    x2    x3\n",
       "0 -0.37  0.06  5.99\n",
       "1 -0.78  1.13  5.59\n",
       "2  0.30  0.56  5.82\n",
       "3  0.78  1.06  8.07\n",
       "4  0.16  0.80  6.30"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = df_train.drop(['target'], axis=1).values, df_train['target'].values\n",
    "x_test = df_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Perceptron Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, activation = 'tanh', learning_rate = 0.01, seed = None, beta = None): \n",
    "        self.activation = activation\n",
    "        self.learning_rate = learning_rate\n",
    "        self.seed = seed\n",
    "        self.x = None\n",
    "        self.x_pred = None\n",
    "        self.w = None        \n",
    "        self.beta = beta\n",
    "        self.g = self.get_activation(self.activation, self.beta)\n",
    "        \n",
    "    def get_activation(self, activation, beta = None):\n",
    "        \"\"\"Returns an activation function\n",
    "            :param activation (str): the name of the function \n",
    "                ['linear', 'unipolar_step', 'bipolar_step', \n",
    "                'logistic', 'simmetric_ramp', 'tanh', 'relu']\n",
    "            :return (lambda function): the implemented activation function\n",
    "        \"\"\"\n",
    "        if activation == 'linear':\n",
    "            g = lambda x: x\n",
    "        elif activation == 'unipolar_step':\n",
    "            g = lambda x: 1 if x >= 0 else 0\n",
    "        elif activation == 'bipolar_step':\n",
    "            g = lambda x: 1 if x >= 0 else -1\n",
    "        elif activation == 'logistic':\n",
    "            g = lambda x, beta: 1/(1 + np.exp(-beta*x))\n",
    "        elif activation == 'simmetric_ramp':\n",
    "            g = lambda x, beta: x if x > -beta or x < beta else beta\n",
    "        elif activation == 'tanh':\n",
    "            g = lambda x, beta: (1 - np.exp(-beta*x))/(1 + np.exp(-beta*x))\n",
    "        elif activation == 'relu':\n",
    "            g = lambda x: x if x > 0 else 0\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "        return g\n",
    "        \n",
    "    def train(self, features, target, max_epochs = 30):\n",
    "        \"\"\" Trains a single neuron perceptron model.\n",
    "            :param features (np.array): an array containg training examples and its features\n",
    "            :param target (np.array): the true values of the output \n",
    "            :max_epochs (int): the maximum number of epochs to train the algorithm\n",
    "        \"\"\"\n",
    "        # Appending a bias constant to the features array\n",
    "        self.x = np.array([np.concatenate(([1], i)) for i in features])\n",
    "        \n",
    "        # Initializing the weights with a random uniform function (0, 1)\n",
    "        self.w = np.array([random.uniform(0,1) for i in np.arange(self.x.shape[1]-1)])\n",
    "        self.w = np.concatenate(([-1], self.w))\n",
    "        \n",
    "        epoch = 1\n",
    "        print (\"Epoch {} >> W = {}\".format(epoch, self.w))\n",
    "        \n",
    "        # Starting training until max_epochs is reached or no error is found\n",
    "        keep_training = True\n",
    "        while (keep_training):          \n",
    "            keep_training = False            \n",
    "            for index, sample in enumerate(self.x):\n",
    "                u = np.dot(sample, p.w)\n",
    "                y = self.g(u)                \n",
    "                if (y != target[index]):\n",
    "                    self.w = self.w + self.learning_rate*(target[index]-y)*sample\n",
    "                    keep_training = True\n",
    "            epoch += 1            \n",
    "            if epoch > max_epochs:\n",
    "                keep_training = False\n",
    "        print (\"Epoch {} >> W = {}\".format(epoch, self.w))\n",
    "        \n",
    "    def predict(self, features):\n",
    "        \"\"\" Predicts the output of a set of test features from a pre-trained model\n",
    "            :params features (np.array): the test set of features\n",
    "            :return y_pred (np.array): the predicted output\n",
    "        \"\"\"\n",
    "        self.x_pred = np.array([np.concatenate(([1], i)) for i in features])\n",
    "        u = np.dot(self.x_pred,p.w)\n",
    "        self.y_pred = list()\n",
    "        for u_i in u:\n",
    "            self.y_pred.append(self.g(u_i))\n",
    "        self.y_pred = np.array(self.y_pred)\n",
    "        return self.y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Starting training  1\n",
      "Epoch 1 >> W = [-1.          0.98216311  0.10435385  0.34794601]\n",
      "Epoch 459 >> W = [ 3.1         1.58116311  2.53535385 -0.72665399]\n",
      "Predictions:  [-1  1  1  1  1  1 -1  1 -1 -1]\n",
      "\n",
      "### Starting training  2\n",
      "Epoch 1 >> W = [-1.          0.59635098  0.63210285  0.25392344]\n",
      "Epoch 426 >> W = [ 3.04        1.51815098  2.49710285 -0.70047656]\n",
      "Predictions:  [-1  1  1  1  1  1 -1  1 -1 -1]\n",
      "\n",
      "### Starting training  3\n",
      "Epoch 1 >> W = [-1.          0.04644378  0.90591823  0.46864117]\n",
      "Epoch 426 >> W = [ 3.          1.53424378  2.45631823 -0.70235883]\n",
      "Predictions:  [-1  1  1  1  1  1 -1  1 -1 -1]\n",
      "\n",
      "### Starting training  4\n",
      "Epoch 1 >> W = [-1.          0.48076392  0.08691916  0.3403141 ]\n",
      "Epoch 420 >> W = [ 3.          1.54636392  2.45971916 -0.7022859 ]\n",
      "Predictions:  [-1  1  1  1  1  1 -1  1 -1 -1]\n",
      "\n",
      "### Starting training  5\n",
      "Epoch 1 >> W = [-1.          0.90883605  0.36047595  0.04567482]\n",
      "Epoch 405 >> W = [ 2.98        1.53663605  2.45707595 -0.69852518]\n",
      "Predictions:  [-1  1  1  1  1  1 -1  1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "for training_index in np.arange(1, 6, 1):\n",
    "    print (\"\\n### Starting training \", training_index)\n",
    "    p = Perceptron(activation='bipolar_step', learning_rate=0.01)        \n",
    "    p.train(features=x_train, target=y_train, max_epochs=2000)      \n",
    "    print (\"Predictions: \", p.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training and prediction 5 times the algorithms no the given train and test set, we can see that, for each round, the output can be different. This is due to the fact that the weights of the perceptron are initialized randomly, which also yields to a different number of training epochs as shown in the log above. \n",
    "\n",
    "Given that the number of epochs did not reach the maximum number of epochs stablished in the model initialization (2000), we can conclude that the perceptron did manage to separate all classes from the train set. As a result, it is possible to affirm that such classes are linearly separable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
